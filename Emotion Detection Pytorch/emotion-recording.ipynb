{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording videos of emotions and splitting into .jpg to train\n",
    "Sources:\n",
    "- https://www.geeksforgeeks.org/saving-a-video-using-opencv/\n",
    "- https://stackoverflow.com/questions/30509573/writing-an-mp4-video-using-python-opencv/54731615#54731615\n",
    "- https://www.youtube.com/watch?v=uL-wCzVMPsc\n",
    "- https://www.geeksforgeeks.org/cropping-faces-from-images-using-opencv-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_emotion(emotion='anger', name_face='name/', video_path='./recordings/'):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3,640)\n",
    "    cap.set(4,480)\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(video_path + name_face):\n",
    "            os.makedirs(video_path + name_face)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory of' + video_path + name_face)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    recording_path = video_path + name_face + emotion + '.mp4'\n",
    "    out = cv2.VideoWriter(recording_path, fourcc, 20.0, (640,480))\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        c = cv2.waitKey(1)\n",
    "        if c & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Emotion into .jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_emotion(emotion='anger', name_face='name/', video_path='./recordings/', frame_path='./frames/'):\n",
    "    # Playing video from file:\n",
    "    cap = cv2.VideoCapture(video_path + name_face + emotion + '.mp4')\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(frame_path + name_face + '/' + emotion):\n",
    "            os.makedirs(frame_path + name_face + '/' + emotion)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory of' + frame_path + name_face + '/' + emotion)\n",
    "\n",
    "    currentFrame = 0\n",
    "    while(currentFrame < length):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if currentFrame > 20 and currentFrame < length - 20 and currentFrame % 3 == 0:\n",
    "            # Saves image of the current frame in jpg file\n",
    "            name = frame_path + name_face + emotion + '/' + str(currentFrame) + '.jpg'\n",
    "            # print ('Creating ' + name)\n",
    "            cv2.imwrite(name, frame)\n",
    "\n",
    "        # To stop duplicate images\n",
    "        currentFrame += 1\n",
    "    \n",
    "    print('Split until ' + name)\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping Faces from Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(emotion='anger', name_face='name/', frame_path='./frames/', data_path = './data/', train_path='train/'):\n",
    "    # Load the cascade\n",
    "    face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "    # Checks to see if path exists, if not, makedir\n",
    "    try:\n",
    "        if not os.path.exists(data_path + name_face + train_path + '/' + emotion):\n",
    "            os.makedirs(data_path + name_face + train_path + '/' + emotion)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory of' + data_path + name_face + train_path + '/' + emotion)\n",
    "    \n",
    "    # for f in [f for f in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, f))]:\n",
    "    #     save_faces(cascade, f)\n",
    "    for file in os.listdir(frame_path + name_face + emotion):\n",
    "        # print(file)\n",
    "\n",
    "        # Read the input image\n",
    "        img = cv2.imread(frame_path + name_face + emotion + '/' + file)\n",
    "        \n",
    "        # Convert into grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # print(gray.shape)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        # print(faces)    # coordinates of where face is\n",
    "        x, y, w, h = faces[0]\n",
    "\n",
    "        cropped_gray = gray[y:y + h, x : x + w]\n",
    "        # plt.imshow(cropped_gray, cmap = plt.cm.gray)    # cmap is important as it allows plt.imshow to properly show grayscale\n",
    "        # print(cropped_gray.shape)\n",
    "\n",
    "        cv2.imwrite(data_path + name_face + train_path + emotion + '/' + file, cropped_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing Cropped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_cropped(emotion='anger', name_face='name/', dim=(48, 48), data_path='./data/', train_path='train/', test_path='test/'):\n",
    "    \n",
    "    # Checks to see if path exists, if not, makedir\n",
    "    try:\n",
    "        if not os.path.exists(data_path + name_face + train_path + emotion):\n",
    "            os.makedirs(data_path + name_face + train_path + emotion)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory of' + data_path + name_face + train_path + emotion)\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(data_path + name_face + test_path + emotion):\n",
    "            os.makedirs(data_path + name_face + test_path + emotion)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory of' + data_path + name_face + test_path + emotion)\n",
    "\n",
    "    for file in os.listdir(data_path + name_face + train_path + emotion):\n",
    "        # print(file)\n",
    "\n",
    "        # Read the input image\n",
    "        img = cv2.imread(data_path + name_face + train_path + emotion + '/' + file)\n",
    "        resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        cv2.imwrite(data_path + name_face + train_path + emotion + '/' + file, resized_img)\n",
    "        # cv2.imwrite(data_path + name_face + test_path + emotion + '/' + file, resized_img)\n",
    "    \n",
    "    source = data_path + name_face + train_path + emotion\n",
    "    dest = data_path + name_face + test_path + emotion\n",
    "    files = os.listdir(source)\n",
    "    no_of_files = len(files) // 5\n",
    "\n",
    "    for file_name in random.sample(files, no_of_files):\n",
    "        shutil.move(os.path.join(source, file_name), dest)\n",
    "        shutil.remove(os.path.join(source, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_face = 'junyi/'\n",
    "video_path = './recordings/'\n",
    "frame_path = './frames/'\n",
    "data_path = './data/'\n",
    "train_path = 'train/'\n",
    "test_path = 'test/'\n",
    "emotion = 'anger'\n",
    "# emotion = 'happy'\n",
    "# emotion = 'neutral'\n",
    "# emotion = 'sad'\n",
    "# emotion = 'surprise'\n",
    "\n",
    "# Removed to hopefully allow for more accurate results\n",
    "# emotion = 'disgust'\n",
    "# emotion = 'fear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split until ./frames/junyi/happy/129.jpg\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Destination path './data/junyi/test/happy\\96.jpg' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\junyi\\Desktop\\Topics\\code\\Emotion Detection Pytorch\\emotion-recording.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/junyi/Desktop/Topics/code/Emotion%20Detection%20Pytorch/emotion-recording.ipynb#ch0000012?line=1'>2</a>\u001b[0m split_emotion(emotion, name_face, video_path, frame_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/junyi/Desktop/Topics/code/Emotion%20Detection%20Pytorch/emotion-recording.ipynb#ch0000012?line=2'>3</a>\u001b[0m crop_face(emotion, name_face, frame_path, data_path, train_path)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/junyi/Desktop/Topics/code/Emotion%20Detection%20Pytorch/emotion-recording.ipynb#ch0000012?line=3'>4</a>\u001b[0m resize_cropped(emotion, name_face, (\u001b[39m48\u001b[39;49m, \u001b[39m48\u001b[39;49m), data_path, train_path, test_path)\n",
      "\u001b[1;32mc:\\Users\\junyi\\Desktop\\Topics\\code\\Emotion Detection Pytorch\\emotion-recording.ipynb Cell 11'\u001b[0m in \u001b[0;36mresize_cropped\u001b[1;34m(emotion, name_face, dim, data_path, train_path, test_path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/junyi/Desktop/Topics/code/Emotion%20Detection%20Pytorch/emotion-recording.ipynb#ch0000009?line=27'>28</a>\u001b[0m no_of_files \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(files) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/junyi/Desktop/Topics/code/Emotion%20Detection%20Pytorch/emotion-recording.ipynb#ch0000009?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m file_name \u001b[39min\u001b[39;00m random\u001b[39m.\u001b[39msample(files, no_of_files):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/junyi/Desktop/Topics/code/Emotion%20Detection%20Pytorch/emotion-recording.ipynb#ch0000009?line=30'>31</a>\u001b[0m     shutil\u001b[39m.\u001b[39;49mmove(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(source, file_name), dest)\n",
      "File \u001b[1;32md:\\Anaconda3\\lib\\shutil.py:786\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/lib/shutil.py?line=783'>784</a>\u001b[0m     real_dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, _basename(src))\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/lib/shutil.py?line=784'>785</a>\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(real_dst):\n\u001b[1;32m--> <a href='file:///d%3A/Anaconda3/lib/shutil.py?line=785'>786</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Error(\u001b[39m\"\u001b[39m\u001b[39mDestination path \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m already exists\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m real_dst)\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/lib/shutil.py?line=786'>787</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Anaconda3/lib/shutil.py?line=787'>788</a>\u001b[0m     os\u001b[39m.\u001b[39mrename(src, real_dst)\n",
      "\u001b[1;31mError\u001b[0m: Destination path './data/junyi/test/happy\\96.jpg' already exists"
     ]
    }
   ],
   "source": [
    "# record_emotion(emotion, name_face, video_path)\n",
    "# split_emotion(emotion, name_face, video_path, frame_path)\n",
    "# crop_face(emotion, name_face, frame_path, data_path, train_path)\n",
    "# resize_cropped(emotion, name_face, (48, 48), data_path, train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_emotion(emotion, name_face, video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split until ./frames/junyi/anger/120.jpg\n"
     ]
    }
   ],
   "source": [
    "split_emotion(emotion, name_face, video_path, frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crops faces into ./data/name/train/emotions\n",
    "crop_face(emotion, name_face, frame_path, data_path, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizes cropped images\n",
    "resize_cropped(emotion, name_face, (48, 48), data_path, train_path, test_path)\n",
    "# ^ alreeady copies train to test\n",
    "# !Xcopy .\\train\\junyi\\happy .\\test\\junyi\\happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
